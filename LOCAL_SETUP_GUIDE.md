# æœ¬åœ°ç¯å¢ƒè®¾ç½®æŒ‡å—

æœ¬æŒ‡å—å¸®åŠ©ä½ åœ¨æœ¬åœ°ç¯å¢ƒé…ç½® DenseGNN å’Œä¸‹è½½ JARVIS æ•°æ®é›†ã€‚

## 1. ç¯å¢ƒå‡†å¤‡

### 1.1 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰

```bash
# ä½¿ç”¨ conda
conda create -n densegnn python=3.9
conda activate densegnn

# æˆ–ä½¿ç”¨ venv
python -m venv densegnn_env
source densegnn_env/bin/activate  # Linux/Mac
# æˆ–
densegnn_env\Scripts\activate  # Windows
```

### 1.2 å®‰è£…ä¾èµ–åŒ…

```bash
# æ ¸å¿ƒä¾èµ–
pip install numpy==1.26.4 tensorflow==2.15.0 scikit-learn pandas scipy matplotlib
pip install tensorflow-addons networkx sympy pyyaml ase h5py

# PyMatGen åŠå…¶ä¾èµ–
pip install pymatgen monty tabulate tqdm uncertainties spglib plotly palettable

# JARVIS å·¥å…·
pip install jarvis-tools

# å…¶ä»–å·¥å…·
pip install brotli click
```

### 1.3 å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/Guanghui501/densegnn-text.git
cd densegnn-text

# åˆ‡æ¢åˆ°è®­ç»ƒåˆ†æ”¯
git checkout claude/train-densegnn-jarvis-zOOFP
```

### 1.4 è®¾ç½® PYTHONPATH

```bash
# Linux/Mac
export PYTHONPATH=/path/to/densegnn-text:$PYTHONPATH

# Windows (PowerShell)
$env:PYTHONPATH="/path/to/densegnn-text;$env:PYTHONPATH"

# æˆ–è€…æ·»åŠ åˆ° ~/.bashrc æˆ– ~/.zshrc (Linux/Mac)
echo 'export PYTHONPATH=/path/to/densegnn-text:$PYTHONPATH' >> ~/.bashrc
source ~/.bashrc
```

## 2. ä¸‹è½½ JARVIS æ•°æ®é›†

### 2.1 ä½¿ç”¨æä¾›çš„ä¸‹è½½è„šæœ¬

```bash
python download_jarvis_bulk_modulus.py
```

### 2.2 æ‰‹åŠ¨ä¸‹è½½ï¼ˆå¦‚æœè„šæœ¬å¤±è´¥ï¼‰

```python
# save as download_manual.py
from jarvis.db.figshare import data as jdata
import pandas as pd
import os

# ä¸‹è½½ JARVIS-DFT æ•°æ®
print("æ­£åœ¨ä¸‹è½½ JARVIS-DFT 3D æ•°æ®é›†...")
dft_3d = jdata(dataset='dft_3d')
print(f"ä¸‹è½½å®Œæˆï¼Œå…± {len(dft_3d)} æ¡è®°å½•")

# æå– bulk_modulus_kv æ•°æ®
dataset_name = 'bulk_modulus_kv'
output_dir = '/home/datasets/jarvis_dft_3d_bulk_modulus_kv'
os.makedirs(output_dir, exist_ok=True)
os.makedirs(os.path.join(output_dir, dataset_name), exist_ok=True)

data_list = []
for i, entry in enumerate(dft_3d):
    if dataset_name in entry and entry[dataset_name] is not None:
        jid = entry.get('jid', f'jid_{i}')
        value = entry[dataset_name]
        data_list.append({'index': jid, dataset_name: value})

        # ä¿å­˜ CIF æ–‡ä»¶
        if 'atoms' in entry:
            from jarvis.core.atoms import Atoms
            atoms = Atoms.from_dict(entry['atoms'])
            cif_file = os.path.join(output_dir, dataset_name, f'{jid}.cif')
            atoms.write_cif(cif_file)

        if (i + 1) % 1000 == 0:
            print(f"å·²å¤„ç† {i + 1}/{len(dft_3d)} æ¡è®°å½•")

# ä¿å­˜ CSV
df = pd.DataFrame(data_list)
csv_file = os.path.join(output_dir, f'{dataset_name}.csv')
df.to_csv(csv_file, index=False)

print(f"\nå®Œæˆï¼")
print(f"å…±ä¿å­˜ {len(df)} æ¡æœ‰æ•ˆæ•°æ®")
print(f"CSV æ–‡ä»¶: {csv_file}")
print(f"CIF æ–‡ä»¶: {os.path.join(output_dir, dataset_name)}/")
```

è¿è¡Œï¼š
```bash
python download_manual.py
```

### 2.3 éªŒè¯æ•°æ®ä¸‹è½½

```bash
# æ£€æŸ¥æ•°æ®ç›®å½•
ls -la /home/datasets/jarvis_dft_3d_bulk_modulus_kv/

# åº”è¯¥çœ‹åˆ°:
# - bulk_modulus_kv.csv
# - bulk_modulus_kv/ (åŒ…å« .cif æ–‡ä»¶)
```

## 3. è¿è¡Œè®­ç»ƒ

### 3.1 æµ‹è¯•æ•°æ®é›†åŠ è½½

```python
# test_dataset.py
from kgcnn.data.datasets.JarvisBulkModulusKvDataset import JarvisBulkModulusKvDataset

print("åŠ è½½ JarvisBulkModulusKvDataset...")
dataset = JarvisBulkModulusKvDataset(reload=False, verbose=10)

print(f"\næ•°æ®é›†ä¿¡æ¯:")
print(f"- æ ·æœ¬æ•°é‡: {len(dataset)}")
print(f"- æ ‡ç­¾åç§°: {dataset.label_names}")
print(f"- æ ‡ç­¾å•ä½: {dataset.label_units}")

# æŸ¥çœ‹ç¬¬ä¸€ä¸ªæ ·æœ¬
sample = dataset[0]
print(f"\nç¬¬ä¸€ä¸ªæ ·æœ¬çš„å±æ€§:")
for key in sample.keys():
    print(f"  - {key}: {type(sample[key])}")
```

è¿è¡Œï¼š
```bash
python test_dataset.py
```

### 3.2 å¼€å§‹è®­ç»ƒ

ä½¿ç”¨ DenseGNN æ¨¡å‹ï¼š

```bash
python training/train_crystal.py \
  --hyper training/hyper/hyper_jarvis_bulk_modulus_kv.py \
  --category DenseGNN \
  --model DenseGNN \
  --make make_model \
  --dataset JarvisBulkModulusKvDataset \
  --seed 42
```

ä½¿ç”¨å…¶ä»–æ¨¡å‹ï¼ˆMegnet, Schnet, CGCNN, coGNï¼‰ï¼š

```bash
# Megnet
python training/train_crystal.py \
  --hyper training/hyper/hyper_jarvis_bulk_modulus_kv.py \
  --category Megnet.make_crystal_model \
  --model Megnet \
  --dataset JarvisBulkModulusKvDataset \
  --seed 42

# Schnet
python training/train_crystal.py \
  --hyper training/hyper/hyper_jarvis_bulk_modulus_kv.py \
  --category Schnet.make_crystal_model \
  --model Schnet \
  --dataset JarvisBulkModulusKvDataset \
  --seed 42
```

### 3.3 åœ¨ GPU ä¸Šè®­ç»ƒ

```bash
# ä½¿ç”¨ç¬¬ä¸€ä¸ª GPU
python training/train_crystal.py \
  --hyper training/hyper/hyper_jarvis_bulk_modulus_kv.py \
  --category DenseGNN \
  --model DenseGNN \
  --make make_model \
  --dataset JarvisBulkModulusKvDataset \
  --gpu 0 \
  --seed 42

# ä½¿ç”¨å¤šä¸ª GPU
python training/train_crystal.py \
  --hyper training/hyper/hyper_jarvis_bulk_modulus_kv.py \
  --category DenseGNN \
  --model DenseGNN \
  --make make_model \
  --dataset JarvisBulkModulusKvDataset \
  --gpu 0 1 \
  --seed 42
```

### 3.4 è®­ç»ƒç‰¹å®šæŠ˜ï¼ˆfoldï¼‰

```bash
# åªè®­ç»ƒç¬¬ 0 æŠ˜
python training/train_crystal.py \
  --hyper training/hyper/hyper_jarvis_bulk_modulus_kv.py \
  --category DenseGNN \
  --model DenseGNN \
  --make make_model \
  --dataset JarvisBulkModulusKvDataset \
  --fold 0 \
  --seed 42

# è®­ç»ƒç¬¬ 0, 1, 2 æŠ˜
python training/train_crystal.py \
  --hyper training/hyper/hyper_jarvis_bulk_modulus_kv.py \
  --category DenseGNN \
  --model DenseGNN \
  --make make_model \
  --dataset JarvisBulkModulusKvDataset \
  --fold 0 1 2 \
  --seed 42
```

## 4. æŸ¥çœ‹è®­ç»ƒç»“æœ

è®­ç»ƒç»“æœä¿å­˜åœ¨ `results/` ç›®å½•ä¸‹ï¼š

```bash
# æŸ¥çœ‹ç»“æœç›®å½•
ls -la results/JarvisBulkModulusKvDataset/

# ç»“æœæ–‡ä»¶åŒ…æ‹¬:
# - history_fold_0.pickle: è®­ç»ƒå†å²
# - weights_fold_0.h5: æ¨¡å‹æƒé‡
# - model_fold_0.keras: å®Œæ•´æ¨¡å‹
# - predict_fold_0.png: é¢„æµ‹ vs çœŸå®å€¼å›¾è¡¨
# - scaler_fold_0/: æ ‡å‡†åŒ–å™¨
# - score.yaml: æ€§èƒ½è¯„ä¼°æŒ‡æ ‡
# - DenseGNN_hyper.json: è¶…å‚æ•°é…ç½®
```

æŸ¥çœ‹æ€§èƒ½æŒ‡æ ‡ï¼š

```bash
cat results/JarvisBulkModulusKvDataset/DenseGNN/score.yaml
```

## 5. å¸¸è§é—®é¢˜æ’æŸ¥

### é—®é¢˜ 1: æ•°æ®ç›®å½•ä¸å­˜åœ¨

```bash
# é”™è¯¯: FileNotFoundError: /home/datasets/jarvis_dft_3d_bulk_modulus_kv/bulk_modulus_kv.csv

# è§£å†³æ–¹æ¡ˆ: åˆ›å»ºç›®å½•å¹¶ä¸‹è½½æ•°æ®
mkdir -p /home/datasets/jarvis_dft_3d_bulk_modulus_kv
python download_jarvis_bulk_modulus.py
```

### é—®é¢˜ 2: ModuleNotFoundError: No module named 'kgcnn'

```bash
# è§£å†³æ–¹æ¡ˆ: è®¾ç½® PYTHONPATH
export PYTHONPATH=/path/to/densegnn-text:$PYTHONPATH
```

### é—®é¢˜ 3: ç½‘ç»œä¸‹è½½å¤±è´¥

```bash
# å¦‚æœåœ¨ä»£ç†åé¢ï¼Œè®¾ç½®ä»£ç†
export HTTP_PROXY=http://proxy.example.com:8080
export HTTPS_PROXY=http://proxy.example.com:8080

# æˆ–è€…ç¦ç”¨ä»£ç†
unset HTTP_PROXY
unset HTTPS_PROXY
```

### é—®é¢˜ 4: å†…å­˜ä¸è¶³

ç¼–è¾‘é…ç½®æ–‡ä»¶ `training/hyper/hyper_jarvis_bulk_modulus_kv.py`ï¼Œå‡å° batch_sizeï¼š

```python
"fit": {
    "batch_size": 64,  # ä» 128 æ”¹ä¸º 64 æˆ–æ›´å°
    "epochs": 300,
    ...
}
```

### é—®é¢˜ 5: CUDA/GPU é—®é¢˜

```bash
# æ£€æŸ¥ GPU æ˜¯å¦å¯ç”¨
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"

# å¦‚æœæ²¡æœ‰ GPUï¼Œä½¿ç”¨ CPU
python training/train_crystal.py ... --gpu None
```

## 6. ä½¿ç”¨ Jupyter Notebook

```python
# notebook_example.ipynb
import sys
sys.path.insert(0, '/path/to/densegnn-text')

from kgcnn.data.datasets.JarvisBulkModulusKvDataset import JarvisBulkModulusKvDataset
import numpy as np
import matplotlib.pyplot as plt

# åŠ è½½æ•°æ®é›†
dataset = JarvisBulkModulusKvDataset(reload=False, verbose=10)

# è·å–æ ‡ç­¾
labels = np.array(dataset.obtain_property("graph_labels"))

# å¯è§†åŒ–æ ‡ç­¾åˆ†å¸ƒ
plt.figure(figsize=(10, 6))
plt.hist(labels, bins=50, edgecolor='black')
plt.xlabel('Bulk Modulus (GPa)')
plt.ylabel('Frequency')
plt.title('JarvisBulkModulusKv Dataset - Label Distribution')
plt.grid(True, alpha=0.3)
plt.show()

print(f"ç»Ÿè®¡ä¿¡æ¯:")
print(f"- æœ€å°å€¼: {labels.min():.2f} GPa")
print(f"- æœ€å¤§å€¼: {labels.max():.2f} GPa")
print(f"- å¹³å‡å€¼: {labels.mean():.2f} GPa")
print(f"- æ ‡å‡†å·®: {labels.std():.2f} GPa")
```

## 7. è‡ªå®šä¹‰è®­ç»ƒ

å¦‚æœéœ€è¦è‡ªå®šä¹‰è®­ç»ƒæµç¨‹ï¼Œå¯ä»¥å‚è€ƒ `test.py` æ–‡ä»¶ï¼š

```bash
# å¤åˆ¶å¹¶ä¿®æ”¹
cp test.py my_custom_training.py

# ç¼–è¾‘ my_custom_training.py
# ä¿®æ”¹è¶…å‚æ•°ã€æ¨¡å‹é…ç½®ç­‰

# è¿è¡Œè‡ªå®šä¹‰è®­ç»ƒ
python my_custom_training.py
```

## 8. å®Œæ•´ç¤ºä¾‹è„šæœ¬

ä¿å­˜ä¸º `quick_start.sh`ï¼š

```bash
#!/bin/bash

# 1. æ¿€æ´»ç¯å¢ƒ
conda activate densegnn  # æˆ– source densegnn_env/bin/activate

# 2. è®¾ç½®è·¯å¾„
export PYTHONPATH=/path/to/densegnn-text:$PYTHONPATH

# 3. ä¸‹è½½æ•°æ®ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
# python download_jarvis_bulk_modulus.py

# 4. è¿è¡Œè®­ç»ƒ
python training/train_crystal.py \
  --hyper training/hyper/hyper_jarvis_bulk_modulus_kv.py \
  --category DenseGNN \
  --model DenseGNN \
  --make make_model \
  --dataset JarvisBulkModulusKvDataset \
  --seed 42

echo "è®­ç»ƒå®Œæˆï¼æŸ¥çœ‹ç»“æœï¼š"
ls -la results/JarvisBulkModulusKvDataset/DenseGNN/
```

è¿è¡Œï¼š
```bash
chmod +x quick_start.sh
./quick_start.sh
```

## 9. å‚è€ƒèµ„æº

- **é¡¹ç›®æ–‡æ¡£**: `README.md`, `JARVIS_TRAINING_README.md`
- **JARVIS å®˜ç½‘**: https://jarvis.nist.gov/
- **JARVIS æ–‡æ¡£**: https://jarvis-tools.readthedocs.io/
- **DenseGNN è®ºæ–‡**: æŸ¥çœ‹ `README.md`
- **é—®é¢˜åé¦ˆ**: GitHub Issues

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸš€
